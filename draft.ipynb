{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a03a62f-60bc-4133-b254-a0398041be06",
   "metadata": {},
   "source": [
    "%matplotlib inline"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f5b883143a23a23",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import griddata\n",
    "from plotting import plot_equatorial_pacific\n",
    "from td_utils import clean_jma_data\n",
    "from sst_utils import csv_from_aqua_modis_dataset, csv_from_avhrp_csv\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.stats import gaussian_kde, pearsonr, spearmanr, ttest_ind\n",
    "from scipy.spatial.distance import euclidean, cdist\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import haversine_distances"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2ab3ec2939b6e75b",
   "metadata": {},
   "source": [
    "The NCEI Marine data has no option of narrowing the target data field, i.e longitude and latitude of interest. Since it is of very large size, it was not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a0d4ee9f9bb71d4",
   "metadata": {},
   "source": [
    "data = pd.read_csv('data/Marine_CSV_sample.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d2557c456ae0c5c",
   "metadata": {},
   "source": [
    "data.columns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce065a3eadbb32e8",
   "metadata": {},
   "source": [
    "data[['Latitude', 'Longitude', 'Time of Observation', 'Sea Surface Temperature']]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c08e930d668cb9af",
   "metadata": {},
   "source": [
    "Below is monthly data, collected from various stations in particular area, denoted by the coordinates located in the name of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f474b05960c121a8",
   "metadata": {},
   "source": [
    "data = pd.read_csv('data/40_130_30_140.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c197f56975e81e",
   "metadata": {},
   "source": [
    "data.columns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d5dbd285b8e22a",
   "metadata": {},
   "source": [
    "data[['STATION', 'DATE', 'LATITUDE', 'LONGITUDE', 'SEA_SURF_TEMP']]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dd4d93a5e3372d1",
   "metadata": {},
   "source": [
    "data.groupby(['DATE', 'LATITUDE', 'LONGITUDE'])['SEA_SURF_TEMP'].mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "421a0863ec7980b3",
   "metadata": {},
   "source": [
    "data['SEA_SURF_TEMP'][data['LATITUDE'] < 0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69d943f77a64ec77",
   "metadata": {},
   "source": [
    "data['LATITUDE'].max()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8c23b6198a040687",
   "metadata": {},
   "source": [
    "Below is monthly data downloaded from the https://neo.gsfc.nasa.gov/ website. It is monthly data in .nc format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27729fc7a98cdaee",
   "metadata": {},
   "source": [
    "# reading the dataset for month of July 2024\n",
    "# dataset = xr.open_dataset('data/aqua_modis.20240701_20240731.L3m.MO.SST.sst.9km.nc')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f1922914d9e0dd9",
   "metadata": {},
   "source": [
    "dataset = xr.open_dataset('data/aqua_modis/lanina/2010/AQUA_MODIS.20101201_20101231.L3m.MO.SST.sst.9km.nc')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc68d1c244134067",
   "metadata": {},
   "source": [
    "# reading all variables\n",
    "dataset.variables"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f9b215dbfaff9022",
   "metadata": {},
   "source": [
    "Will have to make trasformation on the dataset in order to get the data needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abf9f3bce529bcf2",
   "metadata": {},
   "source": [
    "# extracting to pandas dataframe\n",
    "raw_data = dataset['sst'].to_dataframe()\n",
    "\n",
    "# droping the multiindex\n",
    "tidy_data = raw_data.reset_index()\n",
    "\n",
    "# filtering lat[20S; 20N]\n",
    "tidy_data = tidy_data[(tidy_data.lat >= -20) & (tidy_data.lat <= 20)]\n",
    "\n",
    "# filtering long[130E -> 180 -> -80 W]\n",
    "tidy_data = tidy_data[(tidy_data.lon >= -180) & (tidy_data.lon <= -80) | (tidy_data.lon >= 130) & (tidy_data.lon <= 180)]\n",
    "\n",
    "# droping na values\n",
    "tidy_data = tidy_data.dropna()\n",
    "\n",
    "# rounding lats and long to 0.5 deg\n",
    "def round_to_nearest_half(x):\n",
    "    return np.round(x * 2) / 2\n",
    "\n",
    "tidy_data.lat = tidy_data.lat.apply(round_to_nearest_half)\n",
    "tidy_data.lon = tidy_data.lon.apply(round_to_nearest_half)\n",
    "\n",
    "# grouping by lat and long and averaging the sst\n",
    "tidy_data = tidy_data.groupby(['lat', 'lon']).sst.mean()\n",
    "\n",
    "# dropping multiindex\n",
    "tidy_data = tidy_data.reset_index()\n",
    "\n",
    "# getting the month\n",
    "current_month = dataset.attrs['time_coverage_start']\n",
    "\n",
    "# convert the string to pd.Timestamp object\n",
    "current_month = pd.to_datetime(current_month)\n",
    "\n",
    "# normalize timestamp\n",
    "current_month = current_month.normalize()\n",
    "\n",
    "# set the month as index of the cleaned data\n",
    "tidy_data.index = pd.Index([current_month] * len(tidy_data))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a34d0cb6439c6ed",
   "metadata": {},
   "source": [
    "# rounding the sst\n",
    "# raw_data.sst.round(1)\n",
    "# since the .round() is not working as expected, np used\n",
    "# np.round(raw_data.sst, 1)\n",
    "# since np is not working, using apply\n",
    "tidy_data.sst = tidy_data.sst.apply(lambda x: round(x, 1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e82cc8eff0e4b87",
   "metadata": {},
   "source": [
    "tidy_data['lon'] = np.where(tidy_data['lon'] < 0, tidy_data['lon'] + 360, tidy_data['lon'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e25ea9e7b7b1857",
   "metadata": {},
   "source": [
    "tidy_data.sort_values(['lat', 'lon'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "721fd3b6657e10a5",
   "metadata": {},
   "source": [
    "# getting both the sst and the quality of the observation\n",
    "combined_raw = dataset[['sst', 'qual_sst']].to_dataframe()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b65dee4e38f00c7",
   "metadata": {},
   "source": [
    "combined_raw = combined_raw.reset_index()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3680c334def0f90",
   "metadata": {},
   "source": [
    "combined_raw.qual_sst.value_counts(dropna=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5d7cf88612de24f8",
   "metadata": {},
   "source": [
    "Not explicitly written which is the most reliable observation, however based on common conventions in quality flags, 0.0 is typically used to indicate the highest quality or most reliable observation. For the purpose of the project, the quality of the data is consider to be at sufficient level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5229c5d54d976765",
   "metadata": {},
   "source": [
    "dataset"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "615bebe8efafe5af",
   "metadata": {},
   "source": [
    "tidy_data"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9c7c13d861b96c71",
   "metadata": {},
   "source": [
    "Lets try and plot the data to see how it looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25ce80def8381dc8",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(30, 10))\n",
    "\n",
    "# contour map\n",
    "lon_grid = np.linspace(tidy_data.lon.min(), tidy_data.lon.max(), 100)\n",
    "lat_grid = np.linspace(tidy_data.lat.min(), tidy_data.lat.max(), 100)\n",
    "lon_grid, lat_grid = np.meshgrid(lon_grid, lat_grid)\n",
    "sst_grid = griddata((tidy_data.lon, tidy_data.lat), tidy_data.sst, (lon_grid, lat_grid), method='linear')\n",
    "plt.contourf(lon_grid, lat_grid, sst_grid, cmap='jet', levels=20)\n",
    "\n",
    "\n",
    "# plt.scatter(tidy_data.lon, tidy_data.lat, c=tidy_data.sst, cmap='jet', alpha=0.7, s=150, vmin=20, vmax=35)\n",
    "plt.colorbar(label='Temperature')\n",
    "\n",
    "x_tick=np.arange(130, 290, 10)\n",
    "x_label=[f'{x}°E' if x <= 180 else f'{360 - x}°W' for x in x_tick]\n",
    "\n",
    "y_tick = np.arange(-20, 25, 5)\n",
    "y_label = [f'{np.abs(x)}°S' if x < 0 else f'{np.abs(x)}°N' for x in y_tick]\n",
    "\n",
    "box = plt.Rectangle((190, -5), 50, 10, linewidth=2, edgecolor='RED', facecolor='none')\n",
    "plt.gca().add_patch(box)\n",
    "\n",
    "plt.axhline(y=0)\n",
    "\n",
    "plt.xticks(ticks=x_tick, labels=x_label)\n",
    "plt.yticks(ticks=y_tick, labels=y_label)\n",
    "\n",
    "plt.xlim(130, 280)\n",
    "plt.ylim(-20, 20)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title(f'Equatorian Distribution of SST for {current_month.month_name()}-{current_month.year}')  # Title of the plot\n",
    "plt.show()  # Display the plot"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "472903e02cbbd625",
   "metadata": {},
   "source": [
    "The anomalies observed on the NE and SW quadrants of the diagram are false measurments taken at the earth surface.\n",
    "We need to extract the python code of reading a dataset and converting it to clean and tidy csv to a function and in addition, to be able to read dirs reccursivly and apply the transformation to all datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9cb92a155a6e66",
   "metadata": {},
   "source": [
    "The below code is written in a separate module 'utils.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5556a26cd10f7951",
   "metadata": {},
   "source": [
    "# result_list = extract_datasets('data/aqua_modis/elnino/2015/')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fcb1f852cf9b0f2",
   "metadata": {},
   "source": [
    "# dataset = result_list"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "492d1f6d37b19191",
   "metadata": {},
   "source": [
    "# df = create_dataframe('esno_2015', *dataset)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d494ec43c074b0f",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data/csv_ready/elnino_2015.csv', index_col=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "847c51d48c9690e7",
   "metadata": {},
   "source": [
    "After having the combined dataframes I can extract each month data using a 'for' loop and anallyze the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dafcf4adc8bd076",
   "metadata": {},
   "source": [
    "for index, data in df.groupby(df.index):\n",
    "    print(index, data.sst.mean())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffc9d8cf7b23049",
   "metadata": {},
   "source": [
    "for index, data in df.groupby(df.index):\n",
    "    print(index, data.sst.median())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5d4541dfa4895cb0",
   "metadata": {},
   "source": [
    "This is of no use. I need to filter the data for Niño 3.4 region (5°N-5°S, 170°W-120°W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e2c1714baa4ab0d",
   "metadata": {},
   "source": [
    "df_enso_region = df[(df.lat >= -5) & (df.lat <= 5) | (df.lon >= -170) & (df.lon <= -120)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b8df995f12f909f",
   "metadata": {},
   "source": [
    "df_enso_region.index = pd.to_datetime(df_enso_region.index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "192e7f676443f7d5",
   "metadata": {},
   "source": [
    "df_enso_region"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e812d7006920b6db",
   "metadata": {},
   "source": [
    "for date, data in df_enso_region.groupby(df_enso_region.index):\n",
    "    print(date, f'Mean: {data.sst.mean().round(2)}, Median: {data.sst.median()}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "949a874ff9766e08",
   "metadata": {},
   "source": [
    "Lets export plotting of the equatorial pacific ocean to a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46aea3862a291e0b",
   "metadata": {},
   "source": [
    "df_enso = df[(df.lat >= -5) & (df.lat <= 5) & (df.lon >= 190) & (df.lon <= 240)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e5a3e0743779ef2",
   "metadata": {},
   "source": [
    "df.index = pd.to_datetime(df.index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb7bb124b5d25a1d",
   "metadata": {},
   "source": [
    "df.sst = df.sst.apply(lambda x: None if x > 33 else x)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2c18a51f8c962ad",
   "metadata": {},
   "source": [
    "df = df.dropna()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2196f9c634bff7c",
   "metadata": {},
   "source": [
    "plot_equatorial_pacific(path='data/csv_ready/elnino_2015.csv', cond_name='El Nino')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e98cf9efa803d234",
   "metadata": {},
   "source": [
    "Found out that my extracting function is not working as expected. Fixed it. I have the dataframe saved as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15622342da649aa",
   "metadata": {},
   "source": [
    "Lets extract la nina and see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "815a706a51ab174",
   "metadata": {},
   "source": [
    "# lanina = extract_datasets('data/aqua_modis/lanina/2010/')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de3262e0de9236d5",
   "metadata": {},
   "source": [
    "# lanina = create_dataframe('lanina_2010', *lanina)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab79469175c16b50",
   "metadata": {},
   "source": [
    "lanina = csv_from_aqua_modis_dataset('data/aqua_modis/lanina/2010/', 'lanina_2010')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d0a35d53bcfb29a",
   "metadata": {},
   "source": [
    "lanina.sst = lanina.sst.apply(lambda x: None if x > 33 else x)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6805b9062f73d59f",
   "metadata": {},
   "source": [
    "lanina = lanina.dropna()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ffeec143d4e72dc7",
   "metadata": {},
   "source": [
    "plot_equatorial_pacific('data/csv_ready/lanina_2010.csv', cond_name='La Nina')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d3784d4acbb6d03c",
   "metadata": {},
   "source": [
    "The data before 2002 is provided from a different satelite. \n",
    "The data is in csv format, without indication of the lats and longs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b6884f9dbefb511",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data/aqua_modis/elnino/1997/AVHRR_SST_M_1998-01-01_rgb_720x360.CSV', header=None)\n",
    "lat = np.arange(-90, 90, 0.5)\n",
    "lon = np.arange(-180, 180, 0.5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "717a8155d85a9545",
   "metadata": {},
   "source": [
    "df.columns = lon"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e5f5e78cf0c3953",
   "metadata": {},
   "source": [
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1b51a6c2066eb6e",
   "metadata": {},
   "source": [
    "df['lat'] = lat"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc70b11e94ed4aca",
   "metadata": {},
   "source": [
    "df = df.melt(id_vars='lat', var_name='lon', value_name='sst')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2171752f112d174a",
   "metadata": {},
   "source": [
    "df = df[(df.lat >= -20) & (df.lat <= 20)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2eaf5737debd3f32",
   "metadata": {},
   "source": [
    "df = df[(df.lon >= -180) & (df.lon <= -80) | (df.lon >= 130) & (df.lon <= 180)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8497912fa28f4218",
   "metadata": {},
   "source": [
    "df = df.reset_index(drop=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7fec1ebf86d2767b",
   "metadata": {},
   "source": [
    "df.sst = df.sst.apply(lambda x: None if x > 100 else x)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f3dfd38a9f1a938",
   "metadata": {},
   "source": [
    "df = df.dropna()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b9720c868b584dc8",
   "metadata": {},
   "source": [
    "df['lon'] = np.where(df['lon'] < 0, df['lon'] + 360, df['lon'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "20a0ebf75053ae9e",
   "metadata": {},
   "source": [
    "It is working as expected. Now to create a python function to read multiple files. Will modify the extract_database() function to read "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aea8d2d2cb9bd53c",
   "metadata": {},
   "source": [
    "date = pd.to_datetime('1998-01')\n",
    "df.index = pd.Index([date] * len(df))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74f44f11ea6bf048",
   "metadata": {},
   "source": [
    "# plot_equatorial_pacific(df, cond_name='El Nino')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81c6cf3762aea900",
   "metadata": {},
   "source": [
    "result = csv_from_avhrp_csv('data/aqua_modis/elnino/1997/', 'elnino_1997', '1997-10')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2bc68f35f12e9ea7",
   "metadata": {},
   "source": [
    "result = result.dropna()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff0b38699dd4bac7",
   "metadata": {},
   "source": [
    "# plot_equatorial_pacific(result, 'El Nino')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1edae400f1cf567c",
   "metadata": {},
   "source": [
    "Lets see how the temp changes over time for the ENSO region. First we get a function to apply ENSO region filter to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28e5c366d195d717",
   "metadata": {},
   "source": [
    "tc_pacific = pd.read_csv('data/hurdat_pacific/hurdat2-nepac-1949-2023-042624.txt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc48d6669ec2bcc0",
   "metadata": {},
   "source": [
    "test = tc_pacific"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b5072980e590408",
   "metadata": {},
   "source": [
    "# drop the index\n",
    "test = test.reset_index()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f06315575c08f50a",
   "metadata": {},
   "source": [
    "# rename columns from 0 to len\n",
    "test.columns = [i for i in range(len(test.columns))]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ffc751bc6a9ef1c6",
   "metadata": {},
   "source": [
    "# drop columns 8 - end\n",
    "test = test.drop(columns=[i for i in test.columns[8:]])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "272c53d69212556",
   "metadata": {},
   "source": [
    "# name the columns\n",
    "test.columns = ['date', 'time', 'consecutive_count', 'type_of_depression', 'lat', 'lon','max_wind_kn', 'min_pressure_mBar']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2fbe1a4140c1cc4c",
   "metadata": {},
   "source": [
    "# changing time col to str \n",
    "test.time = test.time.astype(str)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e6f686d8c9a6991",
   "metadata": {},
   "source": [
    "# trimming time col values\n",
    "test.time = test.time.apply(lambda x: x.strip())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de0aee7b-9e8d-4ff9-8fcb-f3a3456cdbf2",
   "metadata": {},
   "source": [
    "test"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "46facc26a3af925c",
   "metadata": {},
   "source": [
    "def clean_ne_td_data(df):\n",
    "    # reset index\n",
    "    df = df.reset_index()\n",
    "    # rename columns from 0 to len\n",
    "    df.columns = [i for i in range(len(df.columns))]\n",
    "    # drop columns 8 - end\n",
    "    df = df.drop(columns=[i for i in df.columns[8:]])\n",
    "    # name the columns\n",
    "    df.columns = ['date', 'time', 'consecutive_count', 'type_of_depression', 'lat', 'lon', 'max_wind_kn',\n",
    "                  'min_pressure_mBar']\n",
    "\n",
    "    # modify the time\n",
    "    df.time = df.time.astype(str)\n",
    "    df.time = df.time.apply(lambda x: x.strip())\n",
    "\n",
    "    # adding columns, removing non-observation entries\n",
    "    df = export_name_basin_count(df)\n",
    "\n",
    "    # continue to modify time\n",
    "    df.time = df.time.apply(lambda x: x[0:2] + ':' + x[2:] + ':00')\n",
    "    df.time = pd.to_timedelta(df.time)\n",
    "\n",
    "    # strip the column, drop non-valid values and convert to int\n",
    "    df.consecutive_count = df.consecutive_count.apply(lambda x: x.strip())\n",
    "    df = df.drop(df.index[~df.consecutive_count.str.isdigit()])\n",
    "    df = df.drop(df.index[~df.date.str.isdigit()])\n",
    "    df.consecutive_count = df.consecutive_count.astype(int)\n",
    "\n",
    "    # modify date, concatenate with time and set as index\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df.date = df.date + df.time\n",
    "    df.index = pd.Index(df.date)\n",
    "\n",
    "    # drop the time and date\n",
    "    df = df.drop(columns=['time', 'date'])\n",
    "    \n",
    "    # set the lat and lon\n",
    "    df.lat = df.lat.apply(convert_lat_lon_to_number)\n",
    "    df.lon = df.lon.apply(convert_lat_lon_to_number)\n",
    "\n",
    "    # rearrange cols\n",
    "    df = df[['basin', 'name', 'consecutive_count', 'type_of_depression', 'lat', 'lon', 'max_wind_kn',\n",
    "       'min_pressure_mBar']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def convert_lat_lon_to_number(value):\n",
    "    return float(value[:-1]) if (value[-1] == 'N' or value[-1] == 'E') else float(value[:-1]) * -1 + 360\n",
    "\n",
    "def export_name_basin_count(df):\n",
    "    # adding additional cols for the type, name\n",
    "    df['basin'] = pd.Series()\n",
    "    df['name'] = pd.Series()\n",
    "    \n",
    "    # getting the rows with names\n",
    "    names = df[~df.time.str.isdigit()]\n",
    "\n",
    "    for index in names.index:\n",
    "        basin = str(names.loc[index, 'date'])[:2]\n",
    "        name = names.loc[index, 'time']\n",
    "        count = names.loc[index, 'consecutive_count']\n",
    "\n",
    "        start_index = index + 1\n",
    "        while df.loc[start_index, 'time'].isdigit():\n",
    "            df.loc[start_index, 'basin'] = basin\n",
    "            df.loc[start_index, 'name'] = name\n",
    "            df.loc[start_index, 'consecutive_count'] = count\n",
    "            start_index += 1\n",
    "            if start_index > df.index[-1]:\n",
    "                break\n",
    "        df = df.drop(index)\n",
    "    return df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c0b3a868-2295-4f13-8bb0-e3de856e6c7c",
   "metadata": {},
   "source": [
    "test = export_name_basin_count(test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c1ee6e9b-78a9-46ff-95e5-7377d22fce20",
   "metadata": {},
   "source": [
    "test"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "305228580b147b7a",
   "metadata": {},
   "source": [
    "# strip the column and convert to int\n",
    "test.consecutive_count = test.consecutive_count.apply(lambda x: x.strip())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c85c78d12b349038",
   "metadata": {},
   "source": [
    "# for this dropping non-valid rows\n",
    "test = test.drop(test.index[~test.consecutive_count.str.isdigit()])\n",
    "test = test.drop(test.index[~test.date.str.isdigit()])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "584137b476829942",
   "metadata": {},
   "source": [
    "# setting the type of the col\n",
    "test.consecutive_count = test.consecutive_count.astype(int)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8aea2507bc2cd042",
   "metadata": {},
   "source": [
    "test.type_of_depression = test.type_of_depression.apply(lambda x: str(x).strip())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a6b7814dcf2aa630",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "test.date = pd.to_datetime(test.date)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4b7d8f9d9db87807",
   "metadata": {},
   "source": [
    "test.time = test.time.apply(lambda x: x[0:2] + ':' + x[2:] + ':00')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d148af2ecf6917e",
   "metadata": {},
   "source": [
    "test.time = pd.to_timedelta(test.time)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5ec6fe832691cfb",
   "metadata": {},
   "source": [
    "test.date = test.date + test.time"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "48b9e164f0842877",
   "metadata": {},
   "source": [
    "test.index = pd.Index(test.date)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d90af879e87765ef",
   "metadata": {},
   "source": [
    "test = test.drop(columns=['time', 'date'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "50cfa69a387344b9",
   "metadata": {},
   "source": [
    "def convert_lat_lon_to_number(value):\n",
    "    return float(value[:-1]) if (value[-1] == 'N' or value[-1] == 'E') else float(value[:-1]) * -1 + 360"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "627cc3186b0c8d84",
   "metadata": {},
   "source": [
    "test.lat = test.lat.apply(convert_lat_lon_to_number)\n",
    "test.lon = test.lon.apply(convert_lat_lon_to_number)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3b39eaef7c0a19fd",
   "metadata": {},
   "source": [
    "Now, it looks that the data is cleaned and tydied. We export all in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bd80a583c99bb835",
   "metadata": {},
   "source": [
    "test.min_pressure_mBar.min()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f3f42bc-1cbe-4d2c-8612-09f6ed5038e5",
   "metadata": {},
   "source": [
    "test2 = tc_pacific[-80:]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37381dd0-680e-4f1e-9e30-834e86c538f9",
   "metadata": {},
   "source": [
    "test_2 = pd.read_csv('data/hurdat_pacific/hurdat2-nepac-1949-2023-042624.txt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4008e620-d9f2-4d65-998c-7cf092f34e99",
   "metadata": {},
   "source": [
    "# tt = clean_ne_td_data(test_2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "67fa35a5-79e2-4e10-b535-e3d284290fd9",
   "metadata": {},
   "source": [
    "# tt.to_csv('data/csv_ready/ne_pacific_td.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0de39474-ea5b-4248-853a-5a1523519940",
   "metadata": {},
   "source": [
    "tt = pd.read_csv('data/csv_ready/ne_pacific_td.csv', index_col=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6d927964-3296-4edb-bb43-a314831610ea",
   "metadata": {},
   "source": [
    "tt = tt.drop(tt.index[tt.min_pressure_mBar == -999])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6c67febb-5b0f-4385-a522-6a93049d2031",
   "metadata": {},
   "source": [
    "tt.index = pd.to_datetime(tt.index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "30fe5227-6e70-4994-9040-06664f942798",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "tt[tt.index.year == 1959][-50:]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b9c5ae20-4097-4021-bf44-0e2468472adf",
   "metadata": {},
   "source": [
    "Time to clean the JMA data. It is not in very convenient format se we need to adjust for the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ecc046e1-decd-4ac6-ae07-089e3a655eea",
   "metadata": {},
   "source": [
    "header_col_space = [5, 4, 3, 4, 4, 1, 20, 8]\n",
    "extract_names = pd.read_fwf('data/jma_data/bst_all.txt', widths=header_col_space, header=None)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "637a8c9e-18c7-4506-ab63-fc64a14145af",
   "metadata": {},
   "source": [
    "names = extract_names[extract_names[0] == 66666]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7f1175b3-6a96-4dae-8ecb-feb38aee3c8f",
   "metadata": {},
   "source": [
    "names"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4e76e724-b307-45ab-80e9-6011a967f0de",
   "metadata": {},
   "source": [
    "data_col_space = [8, 4, 2, 4, 5, 5, 13] # manually adjustd\n",
    "full_data = pd.read_fwf('data/jma_data/bst_all.txt', widths=data_col_space, header=None, dtype='str')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "39c0fdb5-15e9-4e3b-9b2b-248c5a2e36a6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "full_data[-50:]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0c28cba1-9a60-404e-9fb5-e1145658a71b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# def clean_jma_data(data_path='data/jma_data/bst_all.txt'):\n",
    "#     # read the data and extract the header rows \n",
    "#     header_col_space = [5, 4, 3, 4, 4, 1, 20, 8]\n",
    "#     extract_names = pd.read_fwf(data_path, widths=header_col_space, header=None)\n",
    "#     names = extract_names[extract_names[0] == 66666]\n",
    "\n",
    "#     # read the data and extract the header rows. the column space is manually adjusted\n",
    "#     data_col_space = [8, 4, 2, 4, 5, 5, 13]\n",
    "#     full_data = pd.read_fwf(data_path, widths=data_col_space, header=None, dtype='str')\n",
    "\n",
    "#     # create a column to contain the names\n",
    "#     full_data['name'] = pd.Series()\n",
    "\n",
    "#     for index in names.index:\n",
    "#         name = names.loc[index, 7]\n",
    "\n",
    "#         start_index = index + 1\n",
    "#         while True:\n",
    "#             full_data.loc[start_index, 'name'] = name\n",
    "#             start_index += 1\n",
    "#             if start_index > full_data.index[-1]:\n",
    "#                 break\n",
    "#             if start_index in names.index:\n",
    "#                 break\n",
    "#         full_data = full_data.drop(index)\n",
    "\n",
    "#     col_names = ['date', 'indicator', 'category', 'lat', 'lon', 'min_pressure_mBar', 'max_wind_kn', 'name']\n",
    "#     full_data.columns = col_names\n",
    "#     full_data = full_data.drop(columns='indicator')\n",
    "\n",
    "#     full_data = cleaning_jma_columns(full_data)\n",
    "#     full_data = modify_jma_date(full_data)\n",
    "\n",
    "#     save_data(full_data, 'jma_td.csv')\n",
    "\n",
    "#     return full_data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "113372ce-4305-41aa-94ab-a4b138b4d758",
   "metadata": {},
   "source": [
    "data = clean_jma_data()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ff13e4ca-63cd-4182-81e4-11385a6ebe1d",
   "metadata": {},
   "source": [
    "data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "de2c11ad-5f55-4c24-aeec-8a52a5d1d152",
   "metadata": {},
   "source": [
    "# df = data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cb83b215-2b1b-467a-826b-f0fec1d5fe33",
   "metadata": {},
   "source": [
    "# df = df.drop(columns='indicator')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3dc55-b303-4f2e-a207-006f78cd4698",
   "metadata": {},
   "source": [
    "# df.max_wind_kn = df.max_wind_kn.apply(lambda x: '000' if pd.isna(x) else x)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f608103-6ab2-4a2e-8823-3119c2fc9102",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# df.max_wind_kn = df.max_wind_kn.astype('int')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15919f34-4473-4155-95ca-16b4dbda5458",
   "metadata": {},
   "source": [
    "# df.min_pressure_mBar = df.min_pressure_mBar.astype(int)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ac0b0-4f07-493c-98f3-95045949342e",
   "metadata": {},
   "source": [
    "# df.lat = df.lat.astype(int).apply(lambda x: x / 10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98019d1-85b7-4dd9-b057-6f7f9a0ee10f",
   "metadata": {},
   "source": [
    "# df.lon = df.lon.astype(int).apply(lambda x: x / 10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48a295-4bfb-4319-89bc-a541cdef440a",
   "metadata": {},
   "source": [
    "# df.date = df.date.apply(jma_date_time)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce48c89a-c3e4-474e-8a76-2168fb492baf",
   "metadata": {},
   "source": [
    "# df.index = pd.Index(df.date)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960d1de0-e43b-4d4b-a1ff-3030b302e238",
   "metadata": {},
   "source": [
    "# df.to_csv('data/csv_ready/jma_td.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7959c77b-5434-4b9f-b194-e5159b703e32",
   "metadata": {},
   "source": [
    "# df = df.drop(columns='date')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2176ab-2c06-4814-971d-8d2a846224b0",
   "metadata": {},
   "source": [
    "def save_data(data, filename):\n",
    "    try:\n",
    "        data.to_csv(f'data/csv_ready/{filename}.csv')\n",
    "    except OSError:\n",
    "        print('Error saving file')\n",
    "\n",
    "def modify_jma_date(df):\n",
    "    df.date = df.date.apply(jma_date_time)\n",
    "    df.index = pd.Index(df.date)\n",
    "    df = df.drop(columns='date')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def cleaning_jma_columns(df):\n",
    "    # wind column\n",
    "    df.max_wind_kn = df.max_wind_kn.apply(lambda x: '000' if pd.isna(x) else x)\n",
    "    df.max_wind_kn = df.max_wind_kn.astype('int')\n",
    "\n",
    "    # pressure column\n",
    "    df.min_pressure_mBar = df.min_pressure_mBar.astype(int)\n",
    "\n",
    "    # latitude\n",
    "    df.lat = df.lat.astype(int).apply(lambda x: x / 10)\n",
    "\n",
    "    # longitude\n",
    "    df.lon = df.lon.astype(int).apply(lambda x: x / 10)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def jma_date_time(value):\n",
    "    \"\"\" will be applied to all values in the column \"\"\"\n",
    "\n",
    "    date = value[:-2]\n",
    "    time = value[-2:]\n",
    "\n",
    "    time = pd.Timedelta(hours=int(time))\n",
    "\n",
    "    date = f'{date[:2]}-{date[2:4]}-{date[-2:]}'\n",
    "\n",
    "    if int(date[:2]) < 51:\n",
    "        date = '20' + date\n",
    "    else:\n",
    "        date = '19' + date\n",
    "\n",
    "    date = pd.to_datetime(date)\n",
    "\n",
    "    date += time\n",
    "\n",
    "    return date"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8492ba-a136-4ce4-8776-9ddc768f5a51",
   "metadata": {},
   "source": [
    "df_final = clean_jma_data()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b844d0-034f-4f80-a4da-32cc936abde7",
   "metadata": {},
   "source": [
    "# df_final.to_csv('data/csv_ready/jma_td.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dcaf31-3c25-496d-af16-945a52c4f529",
   "metadata": {},
   "source": [
    "jma = pd.read_csv('data/csv_ready/jma_td.csv', index_col=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df270344-a513-4e2b-8558-d8806cb473a4",
   "metadata": {},
   "source": [
    "jma.index = pd.to_datetime(jma.index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "51714127-3c97-4de8-a5d9-ae2aeb0cb9c3",
   "metadata": {},
   "source": [
    "Now that we have the complete data for the TD in north pacific, I will get geo data and convert it to csv so I can plot N Pacific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c6067-ef42-418d-ae3e-d4a265d39b02",
   "metadata": {},
   "source": [
    "jma[(jma.name == 'BOLAVE') & (jma.index.year == 2023)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c85e3a-f2c8-445c-bc5e-6a5497408be9",
   "metadata": {},
   "source": [
    "jma[jma.index.year == 2023].groupby(['name']).value_counts()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e7654-3828-4935-ab1e-6eb0c7b3e5d4",
   "metadata": {},
   "source": [
    "gdf = pd.read_csv('data/csv_ready/gdf_csv.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b279d052-4e93-47d7-8732-47b36ca137a3",
   "metadata": {},
   "source": [
    "gdf = gdf.drop(columns=['id', 'source', 'level', 'parent_id', 'sibling_id', 'area', 'geometry'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f662ca-75b2-48f8-8a66-44186ee746a1",
   "metadata": {},
   "source": [
    "gdf = gdf.drop(columns='geometry')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bdb67e-dda2-41d8-b0b6-950e54e97d2b",
   "metadata": {},
   "source": [
    "gdf.lon = gdf.lon.apply(lambda x: x + 360 if x < 0 else x)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b52e42-e0a1-45ae-b51f-6179b56b4558",
   "metadata": {},
   "source": [
    "gdf = gdf[gdf.lat <= 45]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95319d-2992-4f08-837a-f74a497d9896",
   "metadata": {},
   "source": [
    "gdf = gdf[gdf.lat >= -20]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be13357-5cc3-4b42-80c5-e544d0991094",
   "metadata": {},
   "source": [
    "gdf = gdf[gdf.lon >= 100]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c663d009-daed-40a5-8c9e-73e675fc48f6",
   "metadata": {},
   "source": [
    "gdf = gdf[gdf.lon <= 290]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84cf8f-3bea-4f71-b1f4-ac0c50e77891",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.figure(figsize=(30, 10))\n",
    "plt.scatter(gdf.lon, gdf.lat, s=0.5)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a103c56e-c8dd-4c2e-9594-4adfb73d9af4",
   "metadata": {},
   "source": [
    "# gdf.to_csv('data/csv_ready/gdf_pacific.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4084248-27ab-4424-bc77-5ad44f912f69",
   "metadata": {},
   "source": [
    "pd.read_csv('data/csv_ready/gdf_pacific.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232e3c01-df56-46fc-b9a1-dc5b003bcd8a",
   "metadata": {},
   "source": [
    "jma_2023 = jma[jma.index.year == 2023]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d97161-9a83-4300-94cc-befd21225c9a",
   "metadata": {},
   "source": [
    "jma_2023[jma_2023.name == 'KHANU']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c74c98-f13e-4df4-8682-4d8e1d36cbbd",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(30, 10))\n",
    "plt.scatter(gdf.lon, gdf.lat, s=0.5)\n",
    "\n",
    "for td_name, values in jma_2023.groupby('name'):\n",
    "    plt.plot(values['lon'], values['lat'], label=td_name)    \n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508d370-b492-49a9-affd-f09fdb1c1edb",
   "metadata": {},
   "source": [
    "from sst_utils import read_files, dataset_to_csv\n",
    "from plotting import plot_equatorial_pacific"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd55c7-011b-429a-83e3-7d9b0df4d0be",
   "metadata": {},
   "source": [
    "result = read_files(directory_name='data/aqua_modis/neutral/', ext='nc')\n",
    "# neutral_csv = dataset_to_csv('neutral_2012', result)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7a160-5418-4be0-ae80-c53302bbd9ed",
   "metadata": {},
   "source": [
    "neutral = pd.read_csv('data/csv_ready/neutral_2012.csv', index_col=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f0bd9b-536f-4c7e-ba2e-b186a8db6557",
   "metadata": {},
   "source": [
    "neutral.index = pd.to_datetime(neutral.index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64daec1-5b51-4ad0-a820-a3de82605d73",
   "metadata": {},
   "source": [
    "neutral.index = pd.to_datetime(neutral.index)neutral.index = pd.to_datetime(neutral.index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39ffce6-ddf1-4d2d-bfb6-fe6fe92d7725",
   "metadata": {},
   "source": [
    "elnino = pd.read_csv('data/csv_ready/elnino_2015.csv', index_col=0)\n",
    "elnino.index = pd.to_datetime(elnino.index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df730c76-3b48-4c52-a1d5-1c8f8f886400",
   "metadata": {},
   "source": [
    "elnino"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920aa04e-91ee-44ae-8229-6a8098a7abaf",
   "metadata": {},
   "source": [
    "# result = read_files(directory_name='data/aqua_modis/lanina/2010/', ext='nc')\n",
    "# lanina = dataset_to_csv('lanina_2010', result)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540bf895-3908-4666-ad29-dd97bc9154a4",
   "metadata": {},
   "source": [
    "table = pd.read_table('data/year_period.txt', header=None)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941da86-b270-4d08-a05d-187bf3aa7e75",
   "metadata": {},
   "source": [
    "cols = ['date', 'djf','jfm','fma','mam','amj','mjj','jja','jas','aso','son','ond','ndj']\n",
    "table.columns = cols"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d16838-cbb0-4a14-bd2d-c7a4a845227d",
   "metadata": {},
   "source": [
    "table['enso'] = pd.Series()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce957c-33e0-4ab7-9d9e-3b895214a690",
   "metadata": {},
   "source": [
    "table.loc[0, 'enso'] = -1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b094db-1cfa-4d79-8940-f7578d82716e",
   "metadata": {},
   "source": [
    "def apply_enso(df):\n",
    "    for i in range(len(df)):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if df.ndj[i - 1] > 0.5:\n",
    "            df.loc[i, 'enso'] = 1\n",
    "        elif df.ndj[i - 1] < -0.5:\n",
    "            df.loc[i, 'enso'] = -1\n",
    "        else:\n",
    "            df.loc[i, 'enso'] = 0\n",
    "    return df\n",
    "table = apply_enso(table)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6747d5ab-daf6-4463-bb71-f1826fba0355",
   "metadata": {},
   "source": [
    "table.enso.value_counts()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e55b35-e691-4192-bdcd-8218aa989b63",
   "metadata": {},
   "source": [
    "cols = ['date', 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 'enso']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6641d4b3-f6e8-4638-bfd6-9f3a9ef8ef54",
   "metadata": {},
   "source": [
    "table.columns = cols"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ff968-f99d-42b1-9a6b-ba43118e26f6",
   "metadata": {},
   "source": [
    "table = table.melt(id_vars=['date', 'enso'], var_name='month', value_name='sst_anomaly').sort_values(['date', 'month'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d667c-77b2-41ef-9952-ee2fd18d2981",
   "metadata": {},
   "source": [
    "def concat_year_month(df):\n",
    "    df.date = df.date.astype(str)\n",
    "    df.month = df.month.astype(str)\n",
    "    for i in range(len(df)):\n",
    "        month = df.loc[i, 'month']\n",
    "        year = df.loc[i, 'date']\n",
    "        if len(month) == 1:\n",
    "            month = '0' + month\n",
    "        df.loc[i, 'date'] = f'{year}-{month}'\n",
    "\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df.index = pd.Index(df.date)\n",
    "    df = df.drop(columns=['date','month'])\n",
    "    return df\n",
    "table = concat_year_month(table)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c37c0-6eee-4d51-9a1e-ec00d9776150",
   "metadata": {},
   "source": [
    "# table.to_csv('data/csv_ready/oni_table.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da9e138-457f-4bcc-b6b8-401d78ad98c2",
   "metadata": {},
   "source": [
    "table = pd.read_table('data/year_period.txt', header=None)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38865f65-ae32-420a-95c7-ee5b46b0a491",
   "metadata": {},
   "source": [
    "cols = ['date', 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "table.columns = cols"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787e3ee9-f390-4b71-864d-64f3c46d21d7",
   "metadata": {},
   "source": [
    "table['sst_anomaly'] = pd.Series()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0831946e-68be-4cfb-a446-9d227a7fc434",
   "metadata": {},
   "source": [
    "def get_four_month_mean_anomaly(df):\n",
    "    for i in range(len(df)):\n",
    "        if i - 1 < 0:\n",
    "            continue\n",
    "        df.loc[i, 'sst_anomaly'] = (df.loc[i - 1, 10] + df.loc[i - 1, 11] + df.loc[i - 1, 12] + df.loc[i, 1]) / 4\n",
    "\n",
    "    df = df.drop(columns=[i for i in range(1, 13)])\n",
    "    return df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ead981-2fc2-4f0a-8ae8-1ffb1ca86a7e",
   "metadata": {},
   "source": [
    "table = get_four_month_mean_anomaly(table)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed82911-2d6a-4558-8fcc-dd4d4f23cfc0",
   "metadata": {},
   "source": [
    "# table.to_csv('data/csv_ready/oni_temp.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae79f4-e161-41ae-8851-7351d259d6cb",
   "metadata": {},
   "source": [
    "table"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d9e9e45-63c8-417a-a09a-c6c8bc9bedc7",
   "metadata": {},
   "source": [
    "def get_dfs():\n",
    "    oni_table = pd.read_csv('data/csv_ready/oni_table.csv', index_col=0)\n",
    "    oni_temp = pd.read_csv('data/csv_ready/oni_temp.csv', index_col=0)\n",
    "    oni_table.index = pd.to_datetime(oni_table.index)\n",
    "    enso_phase = oni_table.groupby(oni_table.index.year)['enso'].apply(lambda x: x.unique()[0])\n",
    "\n",
    "    jma = pd.read_csv('data/csv_ready/jma_td.csv', index_col=0)\n",
    "    jma.index = pd.to_datetime(jma.index)\n",
    "    frequency_jma = jma.groupby(jma.index.year)['name'].nunique()\n",
    "    frequency_jma = pd.merge(frequency_jma, enso_phase, on='date')\n",
    "    frequency_jma.columns = ['frequency', 'enso']\n",
    "\n",
    "    nhc = pd.read_csv('data/csv_ready/ne_pacific_td.csv', index_col=0)\n",
    "    nhc.index = pd.to_datetime(nhc.index)\n",
    "    frequency_nhc = nhc.groupby(nhc.index.year)['name'].nunique()\n",
    "    frequency_nhc = pd.merge(frequency_nhc, enso_phase, on='date')\n",
    "    frequency_nhc.columns = ['frequency', 'enso']\n",
    "\n",
    "    nhc_cp = nhc[nhc.basin == 'CP']\n",
    "    frequency_nhc_cp = nhc_cp.groupby(nhc_cp.index.year)['name'].nunique()\n",
    "    frequency_nhc_cp = pd.merge(frequency_nhc_cp, enso_phase, on='date')\n",
    "    frequency_nhc_cp.columns = ['frequency', 'enso']\n",
    "\n",
    "    nhc_ep = nhc[nhc.basin == 'EP']\n",
    "    frequency_nhc_ep = nhc_ep.groupby(nhc_ep.index.year)['name'].nunique()\n",
    "    frequency_nhc_ep = pd.merge(frequency_nhc_ep, enso_phase, on='date')\n",
    "    frequency_nhc_ep.columns = ['frequency', 'enso']\n",
    "\n",
    "    frequency_tables = [\n",
    "        ('NW', frequency_jma),\n",
    "        ('Central', frequency_nhc_cp),\n",
    "        ('NE', frequency_nhc_ep)]\n",
    "\n",
    "    dfs_freq = [frequency_jma, frequency_nhc]\n",
    "\n",
    "    enso_phase_dt = enso_phase.copy()\n",
    "    enso_phase_dt.index = pd.to_datetime(enso_phase.index.astype(str))\n",
    "\n",
    "    merged = pd.merge(jma, enso_phase_dt, left_on=jma.index.year, right_on=enso_phase_dt.index.year, how='left')\n",
    "    merged = merged.set_index(jma.index)\n",
    "    jma_enso = merged.drop(columns='key_0')\n",
    "\n",
    "    merged = pd.merge(nhc, enso_phase_dt, left_on=nhc.index.year, right_on=enso_phase_dt.index.year, how='left')\n",
    "    merged = merged.set_index(nhc.index)\n",
    "    nhc_enso = merged.drop(columns='key_0')\n",
    "\n",
    "    gdf = pd.read_csv('data/csv_ready/gdf_pacific.csv')\n",
    "    return jma_enso, nhc_enso"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fcd5e9e-176f-438f-b861-ba25011746da",
   "metadata": {},
   "source": [
    "jma_enso, nhc_enso = get_dfs()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bddcfdee-a20f-48fa-a3cd-44f71d0814db",
   "metadata": {},
   "source": [
    "gridspace = 11"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d495262-1fe5-484f-ba94-e01f9255e683",
   "metadata": {},
   "source": [
    "lat_grid = np.linspace(10, 20, gridspace)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab3c0ed1-1615-4c5a-b877-99613cf72959",
   "metadata": {},
   "source": [
    "lon_grid = np.linspace(0, 10, gridspace)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6c6521d-c45c-4c90-bba5-f65bc49f2377",
   "metadata": {},
   "source": [
    "lon_grid, lat_grid = np.meshgrid(lon_grid, lat_grid)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbef1222-e0e6-4d38-a1e7-3019abe5faa2",
   "metadata": {},
   "source": [
    "for i in range(gridspace):\n",
    "    for j in range(gridspace):\n",
    "        plt.scatter(lon_grid[i, j], lat_grid[i, j])\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d635c55-d593-44b0-aaca-e9e98e471045",
   "metadata": {},
   "source": [
    "lat = 18.5\n",
    "lon = 2.5\n",
    "gridspace = 11\n",
    "lat_grid = np.linspace(10, 20, gridspace)\n",
    "lon_grid = np.linspace(0, 10, gridspace)\n",
    "plt.scatter(lon, lat)\n",
    "plt.ylim(lat_grid.min(), lat_grid.max())\n",
    "plt.yticks(lat_grid)\n",
    "plt.xlim(lon_grid.min(), lon_grid.max())\n",
    "plt.xticks(lon_grid)\n",
    "plt.grid(visible=True, )\n",
    "plt.show()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
